a. Sparse datasets can make the model explode in size which takes up ram so reducing the number of coefficients
to calculate with greatly reduce the RAM it uses.

b. L1 regularization reduces some parameters to zero which reduces overfitting and increases sparsity.
It also adds a penalty for non-zero coefficients which encourages scarcity.

c. linear_classifier = train_linear_classifier_model(
    learning_rate=0.1,
    # TWEAK THE REGULARIZATION VALUE BELOW
    regularization_strength=0.8,
    steps=300,
    batch_size=100,
    feature_columns=construct_feature_columns(),
    training_examples=training_examples,
    training_targets=training_targets,
    validation_examples=validation_examples,
    validation_targets=validation_targets)
print("Model size:", model_size(linear_classifier))

Model training finished.
Model size: 572