a. A linear model is preferable if the problem is linear in nature. For instance, the and, or, and not function that we studied earlier
are linear and would perform better with a linear model. However, most of the interesting things we want to do with these models are 
non-linear which means that deep networks are generally preferable to linear ones.
b. Yes
c. Embeddings would do good for sentiment analysis because it uses sparce datasets which are hard for the networks to train on. So using
an embedded comlumn makes the computation easier, although it seems in this case that the network performs worse with the embedded 
column than just the DNN.
d. It seems that negative words that are highly indicative like waste and worst and clumped, words like amazed, perfect and loved are in 
the bottom left and it seems like the question mark is very neutral whereas the excaimation mark tends toward the positive side.
e. Learning rate: 0.15, 5000 steps 

Training set metrics:
accuracy 0.93908
accuracy_baseline 0.5
auc 0.9754216
auc_precision_recall 0.9732076
average_loss 0.1821665
label/mean 0.5
loss 4.5541625
precision 0.9294265
prediction/mean 0.4997514
recall 0.95032
global_step 5000
---
Test set metrics:
accuracy 0.87152
accuracy_baseline 0.5
auc 0.93785536
auc_precision_recall 0.9372996
average_loss 0.34863076
label/mean 0.5
loss 8.715769
precision 0.8653816
prediction/mean 0.4962415
recall 0.87992
global_step 5000
---
