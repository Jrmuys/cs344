{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "---------------\n",
    "\n",
    "## Exercise 1: Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of Paul Graham's algoritm outlined in \"A Plan for Spam.\" It takes in a known list of words from spam and ham emails and computes the probability that a given word is likely from spam email or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class SpamFilter:\n",
    "    \n",
    "\n",
    "    def __init__(self, spam, ham):\n",
    "        self.spam = []\n",
    "        self.ham = []\n",
    "        \n",
    "        # Fill local lists with the words from the two corpora\n",
    "        for i in spam:\n",
    "            for j in i:\n",
    "                self.spam.append(j.lower())        \n",
    "        for i in ham:\n",
    "            for j in i:\n",
    "                self.ham.append(j.lower())\n",
    "                \n",
    "        self.nbad = len(spam)\n",
    "        self.ngood = len(ham)\n",
    "                \n",
    "        # Counts the number of each word in both of the list and adds those to the hash table\n",
    "        self.spam_hash = collections.Counter(self.spam)\n",
    "        self.ham_hash = collections.Counter(self.ham)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.both = self.spam_hash.copy()\n",
    "        self.both.update(self.ham_hash)\n",
    "        self.probs = self.both.copy()\n",
    "        \n",
    "        for i in self.both.keys():\n",
    "            self.probs[i] = self.find_probabilities(i)\n",
    "\n",
    "    def find_probabilities(self, key):\n",
    "        g = 2 * self.ham_hash[key]\n",
    "        b = self.spam_hash[key]\n",
    "        \n",
    "        if b + g > 1:\n",
    "            return max( 0.01, min(0.99, min(1.0, b/self.nbad) / (min(1.0, g/self.ngood) + min(1.0, b/self.nbad))))\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def spam_filter(self, corpus):\n",
    "        probs = []\n",
    "        for i in corpus:\n",
    "            if i.lower() in self.probs:\n",
    "                probs.append(self.probs[i.lower()])\n",
    "            else:\n",
    "                probs.append(0.4)        \n",
    "        prod = 1\n",
    "        comp_prod = 1\n",
    "        \n",
    "        for i in probs:\n",
    "            prod *= i\n",
    "            comp_prod *= (1 - i)\n",
    "        \n",
    "        return prod / (prod + comp_prod)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table of probabilities (shown below) is then used to compute the likelyhood that a new email is spam or not by passing those words in through an algorithm that adds up all of those probabilities. The sample corpora are from the problem definition. The first email test should come out spam becasue it contains the words \"I am spam\" which are all indicators of spam email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'am': 0.99, 'spam': 0.99, 'i': 0.5, 'do': 0.3333333333333333, 'like': 0.3333333333333333, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01, 'not': 0, 'that': 0, 'spamiam': 0})\n"
     ]
    }
   ],
   "source": [
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "spam_filter = SpamFilter(spam_corpus, ham_corpus)\n",
    "\n",
    "print(spam_filter.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proability of spam is    0.99990, test mail 1 is spam!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_mail_1 = ['I','am','spam']\n",
    "test_mail_1_result = spam_filter.spam_filter(test_mail_1)\n",
    "if test_mail_1_result > 0.9:\n",
    "    print(\"Proability of spam is %10.5f, test mail 1 is spam!\"% test_mail_1_result)\n",
    "else:\n",
    "    print(\"Proability of spam is %10.5f, test mail 1 is ham!\"% test_mail_1_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And behold it does. The next test is the email \"ham i am\" which are all indicators of (or at least are a part of) non spam email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proability of spam is    0.50000, test mail 2 is ham!\n"
     ]
    }
   ],
   "source": [
    "test_mail_2 = ['ham', 'i', 'am']\n",
    "test_mail_2_result = spam_filter.spam_filter(test_mail_2)\n",
    "if test_mail_2_result > 0.9:\n",
    "    print(\"Proability of spam is %10.5f, test mail 2 is spam!\"% test_mail_2_result)\n",
    "else:\n",
    "    print(\"Proability of spam is %10.5f, test mail 2 is ham!\"% test_mail_2_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next test tests the filter on new words that it hasn't seen before, which show that new words are generally considered ham with some uncertainty (0.4 per word), so the email comes out as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proability of spam is    0.16495, test mail 3 is ham!\n"
     ]
    }
   ],
   "source": [
    "test_mail_3 = ['These','are','new','words']\n",
    "test_mail_3_result = spam_filter.spam_filter(test_mail_3)\n",
    "if test_mail_3_result > 0.9:\n",
    "    print(\"Proability of spam is %10.5f, test mail 3 is spam!\"% test_mail_3_result)\n",
    "else:\n",
    "    print(\"Proability of spam is %10.5f, test mail 3 is ham!\"% test_mail_3_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last example shows a mix of both spam and ham words (\"green spam and not ham\"), which shows that the algorithm is biased toward ham, valuing them twice as much as spam words, so it comes out ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proability of spam is    0.00000, test mail 4 is ham!\n"
     ]
    }
   ],
   "source": [
    "test_mail_4 = ['green','spam','and','not', 'ham']\n",
    "test_mail_4_result = spam_filter.spam_filter(test_mail_4)\n",
    "if test_mail_3_result > 0.9:\n",
    "    print(\"Proability of spam is %10.5f, test mail 4 is spam!\"% test_mail_4_result)\n",
    "else:\n",
    "    print(\"Proability of spam is %10.5f, test mail 4 is ham!\"% test_mail_4_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this spam filter is bayesian\n",
    "\n",
    "This algorithm is Bayesian first because it is probabilistic. It uses probabilities to determine if an email is spam or not. It is also Bayesian in that the probabilities are considered independent, each word is considered separately and does not consider which words were around it, the context it was in, or if words \"cause\" other words. This makes the algorithm naive Bayesian because naive Bayes algorithms don't consider dependence. It is also Bayesian in that it combines the probabilities of multiple words into one final solution just as Bayes networks take many probabilities together to find the desired probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "\n",
    "## Exercise 2: Bayesian Networks\n",
    "\n",
    "### a. Implementation of the Bayesian network shown in Figure 14.12a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14.2 - burglary example\n",
    "grass = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.50}),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Compute the number of independent values in the full joint probability distribution for this domain. Assume that no conditional independence relations are known to hold between these values.\n",
    "\n",
    "$\\begin{aligned}\n",
    "    \\textbf values = 2^4\n",
    "        &= 16\n",
    "\\end{aligned}$\n",
    "    \n",
    "### c. Compute the number of independent values in the Bayesian network for this domain. Assume the conditional independence relations implied by the Bayes network.\n",
    "\n",
    "$\\begin{aligned}\n",
    "    \\textbf values = 1+2+2+4\n",
    "        &= 9\n",
    "\\end{aligned}$\n",
    "\n",
    "### d. Compute probabilities for the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute P(Cloudy)\n",
      "False: 0.5, True: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"compute P(Cloudy)\")\n",
    "print(enumeration_ask('Cloudy', dict(), grass).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value comes strait from the diagram.\n",
    "$\\begin{aligned}\n",
    "    \\textbf <0.5, 0.5>\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "P(Sprinker | cloudy)\n",
      "False: 0.9, True: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nP(Sprinker | cloudy)\")\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), grass).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be taken directly from the diagram.\n",
    "$\\begin{aligned}\n",
    "    \\textbf <0.1, 0.9>\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "P(Cloudy| the sprinkler is running and it’s not raining)\n",
      "False: 0.952, True: 0.0476\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nP(Cloudy| the sprinkler is running and it’s not raining)\")\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), grass).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf {P}(cloudy|s, \\urcorner r )\n",
    "    &=\\alpha < P(c, s, \\urcorner r), P(\\urcorner c, s, \\urcorner r) > \\\\\n",
    "    &= \\alpha < P(c) \\cdot P(s|c )\\cdot P(\\urcorner r|c) ,  P(\\urcorner c)  \\cdot P(s|\\urcorner c )\\cdot P(\\urcorner r|\\urcorner c) >\\\\\n",
    "    &= \\alpha < (0.50)(0.20)(0.10) , (0.50)(0.50)(0.80) > \\\\\n",
    "    &= \\alpha < 0.01, 0.2 > \\\\\n",
    "    &= <0.048, 0.952 >\n",
    "\\end{aligned}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
      "False: 0.01, True: 0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nP(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\")\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), grass).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf {P}(Wet|cloudy, sprinker, rain )\n",
    "    &=\\alpha <  P(w, c, s, r), P(\\urcorner w, c, s, r) > \\\\\n",
    "    &= \\alpha < P(w|s,r) P(s|c) P(r|c) P(c), P(\\urcorner w|s,r)P(s|c) P(r|c) P(c) > \\\\\n",
    "    &= \\alpha < (0.99)(0.10)(0.80)(0.50) , (0.01)(0.10)(0.80)(0.50) > \\\\\n",
    "    &= \\alpha < 0.0396, 0.0004 > \\\\\n",
    "    &= <0.99, 0.01 >\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "P(Cloudy | the grass is not wet)\n",
      "False: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nP(Cloudy | the grass is not wet)\")\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), grass).show_approx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "    \\textbf {P}(Cloudy | \\urcorner Wet )\n",
    "    &= \\alpha \\sum_{s,r} P(c,w,s,r) \\\\\n",
    "    &= \\alpha < P(c)P(r|c)P(s|c)P(\\urcorner w|s,r) + P(c)P(\\urcorner r|c)P(s|c)P(\\urcorner w|s,\\urcorner r) \\\\\n",
    "    &           P(c)P(r|c)P(\\urcorner s|c)P(\\urcorner w|\\urcorner s,r) + P(c)P(\\urcorner r|c)P(\\urcorner s|c)P(\\urcorner w|\\urcorner s,\\urcorner r) , \\\\\n",
    "    &           P(\\urcorner c)P(r|\\urcorner c)P(s|\\urcorner c)P(\\urcorner w|s,r) + P(\\urcorner c)P(\\urcorner r|\\urcorner c)P(s|\\urcorner c)P(\\urcorner w|s,\\urcorner r) \\\\\n",
    "    &           P(\\urcorner c)P(r|\\urcorner c)P(\\urcorner s|\\urcorner c)P(\\urcorner w|\\urcorner s,r) + P(\\urcorner c)P(\\urcorner r|\\urcorner c)P(\\urcorner s|\\urcorner c)P(\\urcorner w|\\urcorner s,\\urcorner r)> \\\\\n",
    "    &= \\alpha < (0.50) (0.80) (0.10) (0.01) + (0.50) (0.20 (0.10) (1.00) + \\\\ &(0.50) (0.80) (0.90) (0.10) + (0.50) (0.20) (0.90) (1.00) , \\\\ & (0.50 (0.20) (0.50) (0.01) + (0.50 (0.80) (0.50) (0.10) +  \\\\  & (0.50) (0.20) (0.50) (0.10) + (0.50) (0.80) (0.50) (1.00) > \\\\\n",
    "    &= \\alpha < 0.1272, 0.2255 > \\\\\n",
    "    &= <0.361, 0.639 >\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
